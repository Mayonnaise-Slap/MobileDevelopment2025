# Backend для приложения

Бэкенд приложения представляет собой сервис, который работает
с [API Hacker News](https://github.com/HackerNews/API) для получения и кэширования данных
о публикациях и комментариях. Приложение использует FastAPI для создания асинхронного REST
API.

## Архитектура проекта

Проект состоит из следующих основных компонентов:

1. **FastAPI сервер** - предоставляет REST API для доступа к данным
2. **Task Manager** - управляет фоновыми задачами для загрузки данных из API Hacker News
3. **База данных PostgreSQL** - хранит данные о публикациях и комментариях
4. **Redis** - используется как брокер сообщений для Celery

## Технологический стек

- **Python 3.13** - язык программирования
- **FastAPI** - фреймворк для создания API
- **SQLModel/SQLAlchemy** - ORM для работы с базой данных
- **PostgreSQL** - реляционная база данных
- **Celery** - система распределенных задач
- **Redis** - брокер сообщений для Celery
- **Docker/Docker Compose** - контейнеризация и оркестрация

## Модели данных

Проект использует следующие модели данных:

- **Story** - публикация с полями: id, by (автор), time, kids (дочерние комментарии),
  title, url, score, descendants
- **Comment** - комментарий с полями: id, by (автор), time, kids (дочерние комментарии),
  text, parent
- **ListHolder** - хранит списки идентификаторов публикаций: new_ids, trending_ids

## API Endpoints

Текущая реализация API включает следующие эндпоинты:

- **GET /** - корневой эндпоинт, возвращает приветственное сообщение
- **GET /health** - проверка работоспособности сервиса и соединения с базой данных
- **GET /api/v1/items/{item_id}** - получение публикации с рекурсивной загрузкой
  комментариев
- **GET /api/v1/topstories** - получение списка популярных публикаций
- **GET /api/v1/newstories** - получение списка новых публикаций

## Task Manager

Task Manager отвечает за фоновую загрузку данных из API Hacker News. Он включает:

- **hn_client.py** - асинхронный клиент для работы с API Hacker News
- **tasks.py** - задачи Celery для загрузки данных
- **scheduler.py** - конфигурация Celery Beat для периодического выполнения задач
- **utils.py** - утилиты для работы с базой данных и API

Периодические задачи:

- Загрузка новых публикаций - каждые 20 минут (0, 20, 40 минут каждого часа)
- Загрузка популярных публикаций - каждые 20 минут со смещением (10, 30, 50 минут каждого
  часа)

## Настройка и запуск

### Предварительные требования

- Docker и Docker Compose
- Git

### Запуск проекта

1. Клонировать репозиторий
2. Создать файл `.env` с переменными окружения:
   ```
   POSTGRES_USER=postgres
   POSTGRES_PASSWORD=123
   POSTGRES_DB=postgres
   DATABASE_URL=postgresql+asyncpg://postgres:123@postgres:5432/postgres
   ```
3. Запустить проект с помощью Docker Compose:
   ```bash
   docker compose up -d
   ```

Сервис будет доступен по адресу: http://localhost:8000

## Структура проекта

```
/backend
├── app
│   ├── db
│   │   └── session.py       # Конфигурация подключения к базе данных
│   ├── task_manager
│   │   ├── hn_client.py     # Клиент для API Hacker News
│   │   ├── scheduler.py     # Конфигурация Celery Beat
│   │   ├── tasks.py         # Задачи Celery
│   │   └── utils.py         # Утилиты для работы с БД и API
│   ├── celery_worker.py     # Конфигурация Celery
│   ├── main.py              # Основной файл FastAPI приложения
│   ├── models.py            # Модели данных
│   └── repository.py        # Репозиторий для работы с данными
├── tests                    # Тесты
├── compose.yml              # Конфигурация Docker Compose
├── Dockerfile               # Dockerfile для сборки образа
└── requirements.txt         # Зависимости проекта
```

## Планы на будущее

- Добавление пагинации для списков публикаций
- Оптимизация запросов к базе данных
- Добавление социальных функций (лайки, подписки)
- Интеграция с системами машинного обучения для рекомендаций
